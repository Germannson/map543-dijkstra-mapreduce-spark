{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only for local use\n",
    "#in case problem with PYTHONHASHSEED occurs on cluster see https://www.thoughtvector.io/blog/python-3-on-spark-return-of-the-pythonhashseed/\n",
    "#don't forget to unset on local env afterwards\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"42\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext(\"local[*]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_graph(path_to_file):\n",
    "    \"\"\" read graph in the moodle\"\"\"\n",
    "    res = sc.textFile(path_to_file).map(lambda x : x.split(\"\\t\"))\n",
    "    res = res.flatMap(lambda x : [(x[0], (x[1], int(x[2]))), (x[1], (x[0], int(x[3])))])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_twitter_graph(path_to_file):\n",
    "    \"\"\" read the twitter graph\"\"\"\n",
    "    res = sc.textFile(path_to_file).map(lambda x : tuple(x.split(\" \")))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_generated_graph(path_to_file):\n",
    "    res = sc.textFile(path_to_file).map(lambda x : (x.split(\"\\t\")[0], (x.split(\"\\t\")[1], int(x.split(\"\\t\")[2]))))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = read_generated_graph(\"../graph-data/weighted-graph-100.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', ('71', 5)),\n",
       " ('1', ('93', 19)),\n",
       " ('1', ('14', 7)),\n",
       " ('1', ('23', 11)),\n",
       " ('1', ('67', 4)),\n",
       " ('2', ('4', 7)),\n",
       " ('2', ('92', 18)),\n",
       " ('2', ('37', 18)),\n",
       " ('2', ('79', 12)),\n",
       " ('2', ('22', 1)),\n",
       " ('2', ('52', 8)),\n",
       " ('2', ('55', 17)),\n",
       " ('2', ('81', 10)),\n",
       " ('3', ('96', 12)),\n",
       " ('3', ('8', 4)),\n",
       " ('3', ('35', 5)),\n",
       " ('3', ('15', 10)),\n",
       " ('4', ('85', 10)),\n",
       " ('4', ('87', 20)),\n",
       " ('5', ('74', 15)),\n",
       " ('5', ('35', 1)),\n",
       " ('5', ('40', 3)),\n",
       " ('6', ('52', 2)),\n",
       " ('6', ('24', 20)),\n",
       " ('6', ('67', 18)),\n",
       " ('6', ('40', 7)),\n",
       " ('6', ('15', 18)),\n",
       " ('6', ('19', 2)),\n",
       " ('6', ('58', 12)),\n",
       " ('7', ('5', 7)),\n",
       " ('7', ('89', 13)),\n",
       " ('7', ('17', 13)),\n",
       " ('7', ('43', 14)),\n",
       " ('8', ('2', 14)),\n",
       " ('8', ('55', 16)),\n",
       " ('8', ('39', 11)),\n",
       " ('8', ('66', 11)),\n",
       " ('9', ('24', 18)),\n",
       " ('9', ('87', 17)),\n",
       " ('9', ('59', 14)),\n",
       " ('9', ('20', 14)),\n",
       " ('9', ('17', 14)),\n",
       " ('9', ('70', 1)),\n",
       " ('9', ('80', 15)),\n",
       " ('9', ('100', 19)),\n",
       " ('9', ('10', 12)),\n",
       " ('10', ('76', 2)),\n",
       " ('10', ('66', 9)),\n",
       " ('10', ('31', 13)),\n",
       " ('10', ('92', 13)),\n",
       " ('10', ('61', 6)),\n",
       " ('10', ('45', 9)),\n",
       " ('10', ('42', 10)),\n",
       " ('10', ('96', 12)),\n",
       " ('10', ('1', 1)),\n",
       " ('11', ('81', 15)),\n",
       " ('11', ('83', 17)),\n",
       " ('12', ('94', 1)),\n",
       " ('12', ('41', 17)),\n",
       " ('12', ('34', 19)),\n",
       " ('12', ('17', 9)),\n",
       " ('12', ('69', 13)),\n",
       " ('12', ('42', 8)),\n",
       " ('12', ('62', 19)),\n",
       " ('12', ('10', 11)),\n",
       " ('12', ('98', 5)),\n",
       " ('12', ('30', 16)),\n",
       " ('13', ('34', 19)),\n",
       " ('13', ('2', 15)),\n",
       " ('14', ('66', 10)),\n",
       " ('14', ('55', 3)),\n",
       " ('14', ('3', 3)),\n",
       " ('14', ('15', 1)),\n",
       " ('14', ('94', 18)),\n",
       " ('14', ('88', 9)),\n",
       " ('15', ('22', 14)),\n",
       " ('15', ('88', 8)),\n",
       " ('15', ('74', 13)),\n",
       " ('15', ('58', 10)),\n",
       " ('15', ('97', 11)),\n",
       " ('15', ('7', 19)),\n",
       " ('15', ('71', 1)),\n",
       " ('15', ('36', 12)),\n",
       " ('15', ('47', 8)),\n",
       " ('16', ('84', 12)),\n",
       " ('16', ('62', 8)),\n",
       " ('16', ('99', 8)),\n",
       " ('16', ('75', 6)),\n",
       " ('16', ('81', 14)),\n",
       " ('16', ('79', 19)),\n",
       " ('16', ('80', 14)),\n",
       " ('16', ('46', 19)),\n",
       " ('16', ('42', 2)),\n",
       " ('16', ('39', 14)),\n",
       " ('17', ('77', 8)),\n",
       " ('17', ('57', 6)),\n",
       " ('17', ('72', 5)),\n",
       " ('18', ('71', 7)),\n",
       " ('18', ('100', 11)),\n",
       " ('18', ('86', 10)),\n",
       " ('18', ('16', 3)),\n",
       " ('18', ('14', 13)),\n",
       " ('18', ('27', 7)),\n",
       " ('18', ('63', 20)),\n",
       " ('18', ('6', 18)),\n",
       " ('19', ('47', 5)),\n",
       " ('19', ('42', 13)),\n",
       " ('19', ('96', 2)),\n",
       " ('19', ('45', 15)),\n",
       " ('19', ('44', 15)),\n",
       " ('20', ('71', 7)),\n",
       " ('20', ('99', 1)),\n",
       " ('21', ('89', 19)),\n",
       " ('22', ('82', 16)),\n",
       " ('23', ('96', 17)),\n",
       " ('23', ('90', 10)),\n",
       " ('23', ('38', 9)),\n",
       " ('24', ('52', 4)),\n",
       " ('24', ('85', 18)),\n",
       " ('25', ('15', 9)),\n",
       " ('25', ('22', 15)),\n",
       " ('25', ('71', 18)),\n",
       " ('26', ('68', 11)),\n",
       " ('26', ('20', 11)),\n",
       " ('26', ('99', 14)),\n",
       " ('26', ('25', 8)),\n",
       " ('26', ('84', 10)),\n",
       " ('26', ('10', 8)),\n",
       " ('26', ('50', 15)),\n",
       " ('27', ('85', 17)),\n",
       " ('27', ('71', 13)),\n",
       " ('27', ('76', 8)),\n",
       " ('28', ('99', 18)),\n",
       " ('28', ('53', 17)),\n",
       " ('29', ('17', 8)),\n",
       " ('29', ('29', 16)),\n",
       " ('29', ('40', 15)),\n",
       " ('29', ('60', 4)),\n",
       " ('29', ('3', 11)),\n",
       " ('29', ('70', 15)),\n",
       " ('29', ('92', 11)),\n",
       " ('29', ('49', 15)),\n",
       " ('29', ('90', 16)),\n",
       " ('29', ('46', 15)),\n",
       " ('30', ('39', 3)),\n",
       " ('30', ('63', 2)),\n",
       " ('30', ('28', 9)),\n",
       " ('31', ('70', 15)),\n",
       " ('31', ('72', 2)),\n",
       " ('31', ('40', 11)),\n",
       " ('31', ('22', 20)),\n",
       " ('31', ('77', 16)),\n",
       " ('31', ('65', 6)),\n",
       " ('32', ('58', 16)),\n",
       " ('33', ('70', 11)),\n",
       " ('33', ('95', 5)),\n",
       " ('33', ('87', 17)),\n",
       " ('33', ('83', 12)),\n",
       " ('33', ('4', 3)),\n",
       " ('34', ('95', 8)),\n",
       " ('34', ('98', 12)),\n",
       " ('34', ('5', 4)),\n",
       " ('34', ('53', 6)),\n",
       " ('34', ('46', 13)),\n",
       " ('34', ('94', 3)),\n",
       " ('34', ('71', 6)),\n",
       " ('35', ('98', 15)),\n",
       " ('35', ('9', 14)),\n",
       " ('35', ('21', 17)),\n",
       " ('35', ('95', 13)),\n",
       " ('35', ('48', 2)),\n",
       " ('35', ('25', 5)),\n",
       " ('35', ('87', 5)),\n",
       " ('35', ('6', 16)),\n",
       " ('36', ('80', 14)),\n",
       " ('36', ('14', 8)),\n",
       " ('36', ('49', 1)),\n",
       " ('36', ('26', 1)),\n",
       " ('36', ('38', 3)),\n",
       " ('36', ('75', 11)),\n",
       " ('36', ('85', 7)),\n",
       " ('36', ('11', 11)),\n",
       " ('36', ('23', 19)),\n",
       " ('36', ('33', 11)),\n",
       " ('37', ('76', 6)),\n",
       " ('38', ('37', 10)),\n",
       " ('38', ('24', 18)),\n",
       " ('38', ('65', 3)),\n",
       " ('38', ('18', 4)),\n",
       " ('38', ('47', 8)),\n",
       " ('38', ('27', 10)),\n",
       " ('38', ('8', 15)),\n",
       " ('38', ('1', 9)),\n",
       " ('38', ('71', 6)),\n",
       " ('39', ('86', 2)),\n",
       " ('39', ('66', 3)),\n",
       " ('39', ('6', 14)),\n",
       " ('39', ('7', 8)),\n",
       " ('40', ('19', 13)),\n",
       " ('40', ('16', 8)),\n",
       " ('40', ('71', 17)),\n",
       " ('40', ('29', 10)),\n",
       " ('41', ('27', 15)),\n",
       " ('41', ('28', 3)),\n",
       " ('41', ('41', 2)),\n",
       " ('41', ('50', 18)),\n",
       " ('41', ('66', 9)),\n",
       " ('41', ('1', 7)),\n",
       " ('41', ('100', 12)),\n",
       " ('41', ('34', 12)),\n",
       " ('41', ('8', 4)),\n",
       " ('42', ('49', 14)),\n",
       " ('42', ('58', 8)),\n",
       " ('42', ('5', 16)),\n",
       " ('42', ('33', 11)),\n",
       " ('42', ('37', 19)),\n",
       " ('42', ('61', 19)),\n",
       " ('42', ('96', 11)),\n",
       " ('42', ('26', 5)),\n",
       " ('43', ('75', 18)),\n",
       " ('43', ('18', 15)),\n",
       " ('43', ('48', 3)),\n",
       " ('43', ('98', 17)),\n",
       " ('44', ('94', 20)),\n",
       " ('44', ('71', 7)),\n",
       " ('44', ('85', 15)),\n",
       " ('44', ('40', 15)),\n",
       " ('44', ('86', 11)),\n",
       " ('45', ('100', 1)),\n",
       " ('45', ('54', 5)),\n",
       " ('45', ('8', 17)),\n",
       " ('45', ('37', 1)),\n",
       " ('45', ('14', 13)),\n",
       " ('45', ('4', 14)),\n",
       " ('45', ('70', 11)),\n",
       " ('45', ('69', 2)),\n",
       " ('45', ('94', 6)),\n",
       " ('46', ('21', 17)),\n",
       " ('47', ('84', 6)),\n",
       " ('47', ('12', 2)),\n",
       " ('47', ('57', 20)),\n",
       " ('47', ('15', 11)),\n",
       " ('47', ('27', 1)),\n",
       " ('47', ('47', 17)),\n",
       " ('48', ('59', 7)),\n",
       " ('48', ('44', 2)),\n",
       " ('48', ('7', 7)),\n",
       " ('48', ('55', 14)),\n",
       " ('48', ('81', 5)),\n",
       " ('48', ('24', 8)),\n",
       " ('48', ('29', 16)),\n",
       " ('48', ('77', 17)),\n",
       " ('48', ('65', 2)),\n",
       " ('48', ('54', 5)),\n",
       " ('49', ('15', 16)),\n",
       " ('49', ('39', 16)),\n",
       " ('49', ('93', 14)),\n",
       " ('49', ('89', 4)),\n",
       " ('49', ('19', 6)),\n",
       " ('50', ('19', 18)),\n",
       " ('51', ('83', 7)),\n",
       " ('51', ('10', 8)),\n",
       " ('52', ('12', 19)),\n",
       " ('52', ('63', 11)),\n",
       " ('52', ('58', 13)),\n",
       " ('52', ('98', 5)),\n",
       " ('52', ('73', 11)),\n",
       " ('52', ('90', 1)),\n",
       " ('53', ('6', 7)),\n",
       " ('53', ('16', 17)),\n",
       " ('53', ('60', 17)),\n",
       " ('53', ('40', 7)),\n",
       " ('53', ('88', 17)),\n",
       " ('53', ('23', 10)),\n",
       " ('53', ('13', 13)),\n",
       " ('53', ('30', 2)),\n",
       " ('53', ('94', 7)),\n",
       " ('54', ('78', 17)),\n",
       " ('54', ('54', 5)),\n",
       " ('54', ('99', 9)),\n",
       " ('54', ('64', 10)),\n",
       " ('54', ('43', 7)),\n",
       " ('55', ('18', 16)),\n",
       " ('55', ('79', 13)),\n",
       " ('55', ('51', 17)),\n",
       " ('55', ('84', 8)),\n",
       " ('56', ('30', 10)),\n",
       " ('56', ('32', 13)),\n",
       " ('57', ('82', 18)),\n",
       " ('58', ('21', 5)),\n",
       " ('58', ('90', 8)),\n",
       " ('58', ('40', 18)),\n",
       " ('58', ('72', 4)),\n",
       " ('58', ('3', 7)),\n",
       " ('58', ('50', 17)),\n",
       " ('58', ('82', 8)),\n",
       " ('59', ('78', 3)),\n",
       " ('59', ('43', 20)),\n",
       " ('59', ('76', 9)),\n",
       " ('59', ('3', 17)),\n",
       " ('59', ('100', 11)),\n",
       " ('59', ('93', 15)),\n",
       " ('60', ('58', 2)),\n",
       " ('60', ('3', 17)),\n",
       " ('60', ('66', 8)),\n",
       " ('61', ('4', 14)),\n",
       " ('61', ('27', 6)),\n",
       " ('62', ('7', 10)),\n",
       " ('62', ('33', 14)),\n",
       " ('62', ('24', 20)),\n",
       " ('62', ('26', 16)),\n",
       " ('62', ('71', 17)),\n",
       " ('62', ('2', 5)),\n",
       " ('62', ('20', 20)),\n",
       " ('62', ('93', 7)),\n",
       " ('63', ('89', 19)),\n",
       " ('63', ('47', 9)),\n",
       " ('63', ('18', 18)),\n",
       " ('63', ('67', 2)),\n",
       " ('63', ('51', 3)),\n",
       " ('64', ('32', 3)),\n",
       " ('64', ('35', 12)),\n",
       " ('65', ('86', 10)),\n",
       " ('65', ('67', 9)),\n",
       " ('65', ('14', 9)),\n",
       " ('65', ('81', 4)),\n",
       " ('65', ('80', 14)),\n",
       " ('65', ('15', 13)),\n",
       " ('65', ('32', 14)),\n",
       " ('66', ('88', 7)),\n",
       " ('66', ('70', 1)),\n",
       " ('67', ('47', 4)),\n",
       " ('67', ('20', 12)),\n",
       " ('67', ('71', 18)),\n",
       " ('67', ('68', 10)),\n",
       " ('67', ('35', 20)),\n",
       " ('68', ('69', 20)),\n",
       " ('68', ('53', 20)),\n",
       " ('69', ('30', 14)),\n",
       " ('69', ('54', 15)),\n",
       " ('70', ('8', 2)),\n",
       " ('70', ('1', 5)),\n",
       " ('70', ('15', 11)),\n",
       " ('70', ('40', 14)),\n",
       " ('70', ('45', 14)),\n",
       " ('70', ('41', 7)),\n",
       " ('70', ('74', 18)),\n",
       " ('70', ('89', 13)),\n",
       " ('71', ('69', 2)),\n",
       " ('71', ('63', 16)),\n",
       " ('71', ('90', 7)),\n",
       " ('71', ('64', 13)),\n",
       " ('72', ('44', 13)),\n",
       " ('72', ('59', 13)),\n",
       " ('72', ('74', 11)),\n",
       " ('72', ('36', 11)),\n",
       " ('73', ('88', 3)),\n",
       " ('73', ('33', 17)),\n",
       " ('73', ('35', 3)),\n",
       " ('73', ('72', 17)),\n",
       " ('73', ('65', 3)),\n",
       " ('73', ('75', 4)),\n",
       " ('73', ('47', 5)),\n",
       " ('73', ('24', 14)),\n",
       " ('74', ('94', 9)),\n",
       " ('74', ('66', 1)),\n",
       " ('74', ('84', 3)),\n",
       " ('74', ('60', 5)),\n",
       " ('74', ('10', 9)),\n",
       " ('74', ('25', 14)),\n",
       " ('74', ('82', 14)),\n",
       " ('75', ('48', 19)),\n",
       " ('75', ('96', 14)),\n",
       " ('75', ('71', 20)),\n",
       " ('75', ('12', 4)),\n",
       " ('75', ('79', 11)),\n",
       " ('75', ('6', 17)),\n",
       " ('75', ('29', 5)),\n",
       " ('75', ('100', 6)),\n",
       " ('75', ('38', 11)),\n",
       " ('76', ('5', 8)),\n",
       " ('76', ('65', 10)),\n",
       " ('76', ('56', 13)),\n",
       " ('76', ('100', 7)),\n",
       " ('76', ('95', 6)),\n",
       " ('77', ('81', 19)),\n",
       " ('77', ('94', 3)),\n",
       " ('77', ('87', 15)),\n",
       " ('77', ('5', 1)),\n",
       " ('77', ('3', 7)),\n",
       " ('78', ('87', 6)),\n",
       " ('78', ('40', 20)),\n",
       " ('78', ('11', 13)),\n",
       " ('78', ('4', 1)),\n",
       " ('78', ('79', 4)),\n",
       " ('78', ('44', 8)),\n",
       " ('78', ('83', 19)),\n",
       " ('79', ('61', 3)),\n",
       " ('79', ('47', 19)),\n",
       " ('79', ('54', 19)),\n",
       " ('79', ('20', 18)),\n",
       " ('79', ('48', 12)),\n",
       " ('80', ('91', 17)),\n",
       " ('80', ('37', 20)),\n",
       " ('80', ('24', 15)),\n",
       " ('80', ('50', 19)),\n",
       " ('80', ('35', 16)),\n",
       " ('80', ('25', 3)),\n",
       " ('81', ('79', 13)),\n",
       " ('81', ('82', 12)),\n",
       " ('81', ('36', 10)),\n",
       " ('81', ('57', 3)),\n",
       " ('81', ('3', 18)),\n",
       " ('81', ('26', 12)),\n",
       " ('82', ('24', 13)),\n",
       " ('83', ('25', 2)),\n",
       " ('83', ('80', 8)),\n",
       " ('83', ('75', 20)),\n",
       " ('83', ('100', 13)),\n",
       " ('83', ('81', 6)),\n",
       " ('83', ('83', 4)),\n",
       " ('83', ('21', 16)),\n",
       " ('84', ('11', 5)),\n",
       " ('84', ('21', 11)),\n",
       " ('85', ('11', 2)),\n",
       " ('85', ('59', 4)),\n",
       " ('85', ('37', 19)),\n",
       " ('85', ('61', 1)),\n",
       " ('85', ('95', 18)),\n",
       " ('85', ('69', 1)),\n",
       " ('85', ('76', 12)),\n",
       " ('85', ('35', 13)),\n",
       " ('86', ('39', 4)),\n",
       " ('86', ('29', 6)),\n",
       " ('86', ('58', 6)),\n",
       " ('87', ('39', 15)),\n",
       " ('87', ('24', 3)),\n",
       " ('87', ('79', 2)),\n",
       " ('88', ('6', 8)),\n",
       " ('88', ('98', 1)),\n",
       " ('88', ('36', 3)),\n",
       " ('88', ('34', 14)),\n",
       " ('88', ('20', 10)),\n",
       " ('88', ('2', 4)),\n",
       " ('88', ('56', 15)),\n",
       " ('88', ('58', 2)),\n",
       " ('88', ('100', 6)),\n",
       " ('88', ('21', 4)),\n",
       " ('89', ('28', 1)),\n",
       " ('89', ('50', 12)),\n",
       " ('89', ('58', 6)),\n",
       " ('90', ('19', 9)),\n",
       " ('90', ('7', 2)),\n",
       " ('90', ('70', 5)),\n",
       " ('90', ('92', 13)),\n",
       " ('90', ('51', 20)),\n",
       " ('90', ('27', 4)),\n",
       " ('90', ('62', 12)),\n",
       " ('90', ('31', 10)),\n",
       " ('90', ('47', 17)),\n",
       " ('91', ('71', 15)),\n",
       " ('91', ('65', 19)),\n",
       " ('91', ('64', 5)),\n",
       " ('91', ('39', 16)),\n",
       " ('91', ('60', 13)),\n",
       " ('92', ('85', 17)),\n",
       " ('92', ('63', 10)),\n",
       " ('93', ('39', 18)),\n",
       " ('93', ('50', 13)),\n",
       " ('93', ('87', 17)),\n",
       " ('93', ('23', 11)),\n",
       " ('93', ('60', 4)),\n",
       " ('93', ('36', 9)),\n",
       " ('93', ('3', 9)),\n",
       " ('93', ('83', 11)),\n",
       " ('94', ('7', 1)),\n",
       " ('94', ('60', 18)),\n",
       " ('94', ('80', 6)),\n",
       " ('95', ('4', 1)),\n",
       " ('95', ('35', 4)),\n",
       " ('96', ('16', 3)),\n",
       " ('96', ('83', 19)),\n",
       " ('96', ('47', 3)),\n",
       " ('96', ('82', 14)),\n",
       " ('96', ('53', 18)),\n",
       " ('96', ('85', 6)),\n",
       " ('96', ('79', 7)),\n",
       " ('97', ('43', 19)),\n",
       " ('97', ('72', 2)),\n",
       " ('97', ('75', 16)),\n",
       " ('97', ('51', 20)),\n",
       " ('97', ('69', 11)),\n",
       " ('97', ('63', 5)),\n",
       " ('98', ('59', 3)),\n",
       " ('98', ('26', 15)),\n",
       " ('98', ('48', 14)),\n",
       " ('98', ('79', 15)),\n",
       " ('98', ('95', 13)),\n",
       " ('99', ('82', 4)),\n",
       " ('99', ('94', 3)),\n",
       " ('99', ('7', 16)),\n",
       " ('99', ('25', 5)),\n",
       " ('99', ('46', 8)),\n",
       " ('100', ('50', 16))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## graph non pondéré"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#very small graph\n",
    "directions = sc.parallelize([(1,2),(1,3),(2,4),(3,5),(4,5)])\n",
    "begin = 1\n",
    "end = 5\n",
    "shortest_paths = sc.parallelize([(begin, (0,[]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "directions = read_twitter_graph(\"twitter_combined.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin, end = '15519274', '309366491'\n",
    "shortest_paths = sc.parallelize([(begin, (0,[]))])\n",
    "early_stop = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "CPU times: user 140 ms, sys: 50 ms, total: 190 ms\n",
      "Wall time: 57.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "i = 0\n",
    "while True:\n",
    "    res = shortest_paths.lookup(end)\n",
    "    i+=1\n",
    "    print(i)\n",
    "    if not (res == [] and i < early_stop):\n",
    "        break\n",
    "\n",
    "    shortest_paths = shortest_paths.join(directions).map(lambda x : (x[1][1], (x[1][0][0] + 1 , x[1][0][1] + [x[0]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## graph pondéré"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### V1 (brute force)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connections are denoted (origin, end, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_path(x):\n",
    "    #x is the result of the join operation\n",
    "    # the join should be in format (origin, ((weight_to_origin, path_to_origin, paths_visited_to_origin), (destination, weight_to_destination)))\n",
    "    return (x[1][1][0], (x[1][0][0] + x[1][1][1], x[1][0][1] + [x[0]], {x[0]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortest_path_to_point(x,y):\n",
    "    if x[0] <= y[0]:\n",
    "        res = (x[0], x[1], x[2] | y[2])\n",
    "    else:\n",
    "        res = (y[0], y[1], x[2] | y[2])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for a small graph test\n",
    "directions = sc.parallelize([(1,(2,1)),(1,(3, 5)),(3,(2,2)),(2,(4,2)),(3,(5,2)),(4,(5,2))])\n",
    "begin = 1\n",
    "objective = 5\n",
    "paths_to_objective = set(directions.map(lambda x : (x[1][0] , x[0])).filter(lambda x : x[0] == objective).collect()[0][1])\n",
    "shortest_paths = sc.parallelize([(begin, (0,[],set()))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "directions = read_generated_graph(\"../graph-data/weighted-graph-100.txt\")\n",
    "begin, objective = directions.keys().takeSample(False, 2)\n",
    "paths_to_objective = set(directions.map(lambda x : (x[1][0] , x[0])).filter(lambda x : x[0] == objective).lookup(objective))\n",
    "shortest_paths = sc.parallelize([(begin, (0,[],set()))])\n",
    "early_stop = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[]\n",
      "[]\n",
      "2\n",
      "[]\n",
      "[]\n",
      "3\n",
      "[]\n",
      "[]\n",
      "4\n",
      "[]\n",
      "[]\n",
      "5\n",
      "[('33', (37, ['99', '25', '15', '36'], {'36'}))]\n",
      "[]\n",
      "6\n",
      "[('33', (36, ['99', '25', '15', '88', '36'], {'62', '73', '36'}))]\n",
      "[]\n",
      "7\n",
      "[('33', (36, ['99', '25', '15', '88', '36'], {'62', '42', '73', '36'}))]\n",
      "[]\n",
      "CPU times: user 450 ms, sys: 100 ms, total: 550 ms\n",
      "Wall time: 49.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "i = 0\n",
    "while True:\n",
    "    #stopping criteria\n",
    "    i += 1\n",
    "    print(i)\n",
    "    if i > early_stop :\n",
    "        break\n",
    "    path_found = shortest_paths.filter(lambda x : x[0] == objective).collect()\n",
    "    print(path_found)\n",
    "    print(shortest_paths.lookup(objective))\n",
    "    if path_found != [] and path_found[0][1][2] == paths_to_objective :\n",
    "        break\n",
    "        \n",
    "    #real thing\n",
    "    shortest_paths = shortest_paths.join(directions).map(compute_path).union(shortest_paths)\n",
    "    shortest_paths = shortest_paths.reduceByKey(shortest_path_to_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('33', (36, ['99', '25', '15', '88', '36'], {'36', '42', '62', '73'}))]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortest_paths.filter(lambda x : x[0] == objective).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('99', '33')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "begin, objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_path(x):\n",
    "    #x is the result of the join operation\n",
    "    # the join should be in format (origin, ((weight_to_origin, path_to_origin, paths_visited_to_origin), (destination, weight_to_destination)))\n",
    "    return (x[1][1][0], {\n",
    "                         \"weight_of_path\" : x[1][0][\"weight_of_path\"] + x[1][1][1], \n",
    "                         \"path\" : x[1][0][\"path\"] + [x[0]], \n",
    "                         \"explored_path\" : {x[0]}\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortest_path_to_point(x,y):\n",
    "    if x[\"weight_of_path\"] <= y[\"weight_of_path\"]:\n",
    "        res = {\"weight_of_path\" : x[\"weight_of_path\"], \n",
    "               \"path\" : x[\"path\"], \n",
    "               \"explored_path\" : x[\"explored_path\"] | y[\"explored_path\"]}\n",
    "    else:\n",
    "        res = {\"weight_of_path\" : y[\"weight_of_path\"], \n",
    "               \"path\" : y[\"path\"], \n",
    "               \"explored_path\" : x[\"explored_path\"] | y[\"explored_path\"]}\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for small graph\n",
    "begin = 1\n",
    "objective = 5\n",
    "early_stop = 1\n",
    "directions = sc.parallelize([(1,(2,1)),(1,(3, 5)),(3,(2,2)),(2,(4,2)),(3,(5,2)),(4,(5,2))])\n",
    "paths_to_objective = set(directions.map(lambda x : (x[1][0] , x[0])).lookup(5))\n",
    "shortest_paths = sc.parallelize([(begin, {\"weight_of_path\" :0, \"path\" : [], \"explored_path\" : set()})])\n",
    "points_to_drop = sc.broadcast(set())\n",
    "continue_criteria = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "directions = read_generated_graph(\"../graph-data/weighted-graph-100.txt\")\n",
    "begin, objective = \"99\", \"33\"\n",
    "paths_to_objective = set(directions.map(lambda x : (x[1][0] , x[0])).filter(lambda x : x[0] == objective).lookup(objective))\n",
    "shortest_paths = sc.parallelize([(begin, {\"weight_of_path\" :0, \"path\" : [], \"explored_path\" : set()})])\n",
    "early_stop = 15\n",
    "continue_criteria = True\n",
    "points_to_drop = sc.broadcast(set())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "i = 0\n",
    "while continue_criteria:\n",
    "    new_paths = shortest_paths.join(directions).map(compute_path)\n",
    "    #print(new_paths.collect())\n",
    "    try:\n",
    "        min_new_paths =sc.broadcast(new_paths.map(lambda x : x[1][\"weight_of_path\"]).min())\n",
    "        points_to_drop = sc.broadcast(set(shortest_paths.filter(lambda x : x[1][\"weight_of_path\"] < min_new_paths.value).keys().collect()) | points_to_drop.value)\n",
    "    except ValueError:\n",
    "        #if no new paths are detected\n",
    "        min_new_paths = sc.broadcast(float(\"inf\"))\n",
    "    #print(min_new_paths.value)\n",
    "    shortest_paths = new_paths.union(shortest_paths).reduceByKey(shortest_path_to_point).filter(lambda x : x[0] not in points_to_drop.value)\n",
    "    directions = directions.filter(lambda x : x[0] not in points_to_drop.value and x[1][0] not in points_to_drop.value)\n",
    "    #print(shortest_paths.collect())\n",
    "    \n",
    "    #stopping criteria\n",
    "    continue_criteria = i < early_stop\n",
    "    i +=1\n",
    "    print(i)\n",
    "    try: \n",
    "        #replace by lookup on real machine when hash problem is resolved\n",
    "        path_to_objective = shortest_paths.filter(lambda x : x[0] == objective).collect()\n",
    "        continue_criteria = not path_to_objective[0][1][\"weight_of_path\"] <= min_new_paths.value\n",
    "    except IndexError:\n",
    "        continue_criteria = min_new_paths.value != float(\"inf\")\n",
    "        pass\n",
    "    except KeyError:\n",
    "        continue_criteria = min_new_paths.value != float(\"inf\")\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 155.0 failed 1 times, most recent failure: Lost task 2.0 in stage 155.0 (TID 1795, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 229, in main\n    process()\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 224, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 372, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"<ipython-input-27-f7f1fb2be594>\", line 5, in compute_path\nTypeError: tuple indices must be integers or slices, not str\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:298)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:438)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:421)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:252)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2027)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2048)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2092)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:939)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:938)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:153)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.GeneratedMethodAccessor39.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 229, in main\n    process()\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 224, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 372, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"<ipython-input-27-f7f1fb2be594>\", line 5, in compute_path\nTypeError: tuple indices must be integers or slices, not str\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:298)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:438)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:421)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:252)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-14ad27ac34f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_paths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    822\u001b[0m         \"\"\"\n\u001b[1;32m    823\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m             \u001b[0mport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1158\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1160\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.6-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    319\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 155.0 failed 1 times, most recent failure: Lost task 2.0 in stage 155.0 (TID 1795, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 229, in main\n    process()\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 224, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 372, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"<ipython-input-27-f7f1fb2be594>\", line 5, in compute_path\nTypeError: tuple indices must be integers or slices, not str\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:298)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:438)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:421)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:252)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2027)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2048)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2092)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:939)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:938)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:153)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.GeneratedMethodAccessor39.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 229, in main\n    process()\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 224, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 372, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"<ipython-input-27-f7f1fb2be594>\", line 5, in compute_path\nTypeError: tuple indices must be integers or slices, not str\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:298)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:438)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:421)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:252)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "new_paths.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('6344',\n",
       "  {'explored_path': {'5'},\n",
       "   'path': ['226', '7664', '5'],\n",
       "   'weight_of_path': 1000})]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortest_paths.filter(lambda x : x[0] == objective).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-145-1533247940e0>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-145-1533247940e0>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    3 if (2 ==3)\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
